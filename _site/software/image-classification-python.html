<!DOCTYPE html>
<html>
<head>
  <title>Image Classification using Python and Scikit-learn ‚Äì Gogul Ilango </title>
  
  <link rel="shortcut icon" type="image/png" href="/images/favicon_gi.png"/>
  <link rel="stylesheet" href="https://use.typekit.net/mry7nes.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Rubik:wght@300;400;500&display=swap" rel="stylesheet">

  <script type="text/javascript" src="/js/theme.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=.5, maximum-scale=12.0, minimum-scale=.25, user-scalable=yes"/>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    <meta property="og:title" content="Image Classification using Python and Scikit-learn" />
    <meta name="description" content="Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn." />
    <meta property="og:description" content="Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn." />
    <meta property="twitter:title" content="Image Classification using Python and Scikit-learn" />

    <meta property="og:image" content="https://drive.google.com/uc?id=1XF3KdLLnOrQ2ndwCBCZFdyGXZRM3EIHU"/>
    <meta property="og:image:width" content="180" />
    <meta property="og:image:height" content="110" />

    <meta name="twitter:title" content="Image Classification using Python and Scikit-learn">
    <meta name="twitter:description" content="Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn.">
    <meta name="twitter:image" content="https://drive.google.com/uc?id=1XF3KdLLnOrQ2ndwCBCZFdyGXZRM3EIHU">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Image Classification using Python and Scikit-learn | Gogul Ilango</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Image Classification using Python and Scikit-learn" />
<meta name="author" content="Gogul Ilango" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn." />
<meta property="og:description" content="Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn." />
<link rel="canonical" href="http://localhost:4000/software/image-classification-python" />
<meta property="og:url" content="http://localhost:4000/software/image-classification-python" />
<meta property="og:site_name" content="Gogul Ilango" />
<meta property="og:image" content="https://drive.google.com/uc?id=1XF3KdLLnOrQ2ndwCBCZFdyGXZRM3EIHU" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-01-28T00:00:00+05:30" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://drive.google.com/uc?id=1XF3KdLLnOrQ2ndwCBCZFdyGXZRM3EIHU" />
<meta property="twitter:title" content="Image Classification using Python and Scikit-learn" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Gogul Ilango"},"dateModified":"2017-01-28T00:00:00+05:30","datePublished":"2017-01-28T00:00:00+05:30","description":"Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn.","headline":"Image Classification using Python and Scikit-learn","image":"https://drive.google.com/uc?id=1XF3KdLLnOrQ2ndwCBCZFdyGXZRM3EIHU","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/software/image-classification-python"},"url":"http://localhost:4000/software/image-classification-python"}</script>
<!-- End Jekyll SEO tag -->


  <!--[if lt IE 9]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <!--[if lte IE 8]><script type="text/javascript" src="excanvas.js"></script><![endif]-->
    <meta name="theme-color" content="#000" />
    <link id="main-style-sheet" rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Gogul Ilango - This blog is a personal space of Gogul Ilango who writes about technology, music production, programming and travel." href="/feed.xml" />

  </head>

  <body>
    <div class="outer-wrapping">
      <div class="inner-container">
          <div class="topnav header-right" id="top_navigator">
            <a title="home" id = "nav_home" href="/"><span>home</span></a>
            <a title="music" id = "nav_music" href="https://www.youtube.com/gogulilangomusic" target="_blank"><span>music</span></a>
            <a title="theme" id = "nav_theme" class = "nav_theme" onclick="switchTheme(1)"><span>theme</span></a>
            <a href = "javascript:void(0);" style="font-size:14px;" class="icon" onclick="top_navigation()">&#9776;</a>
          </div>
      </div>
    </div>

    <div id="main" role="main">
      <div class="readtime-progress" id="readtime-progress"></div>

<div class="post-heading post-heading-wrapper post-image">
	<div class="grad-post">
		<h1>Image Classification using Python and Scikit-learn</h1>
		<div class="post-subheading">
			<p>Machine Learning | 28 January 2017</p>
			<p><a href="#show_comments" id="comment-count" class="disqus-comment-count" data-disqus-url="https://gogulilango.com/software/image-classification-python"></a></p>
		</div>
		
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<div class="share-it-box">
<div id="share-box"> 
		<a href="whatsapp://send?text=http://localhost:4000/software/image-classification-python" data-action="share/whatsapp/share"><img class="icon-whatsapp" src="/images/icons/whatsapp.png"/></a>

        <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/image-classification-python" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img class="icon-facebook" src="/images/icons/facebook.png"/></a>
       
        <a href="https://twitter.com/intent/tweet?text=Image Classification using Python and Scikit-learn&url=http://localhost:4000/software/image-classification-python" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"><img class="icon-twitter" src="/images/icons/twitter.png"/></a>

       <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/image-classification-python&title=Image Classification using Python and Scikit-learn&summary=Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn.&source=webjeda" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img class="icon-linkedin" src="/images/icons/linkedin.png"/></a>                               
</div>
</div>
	</div>
</div>

<div class="containing">
	<div class="wrapping">

		<!--<div class="share-box">
	<button class="top-share-fab" id="top-share-fab" onclick="showShareBox(this.id)"></button>
	<div id="top-share-box" class="top-share-box">
		<h5>Share</h5>
		<ul>
			<li class="whatsapp-white"><a href="whatsapp://send?text=http://localhost:4000/software/image-classification-python" data-action="share/whatsapp/share">WhatsApp</a></li>
			<li class="facebook-white"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/image-classification-python" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >Facebook</a></li>
			<li class="twitter-white"><a href="https://twitter.com/intent/tweet?text=Image Classification using Python and Scikit-learn&url=http://localhost:4000/software/image-classification-python" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;">Twitter</a></li>
			<li class="linkedin-white"><a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/image-classification-python&title=Image Classification using Python and Scikit-learn&summary=Learn how to use Global Feature Descriptors such as RGB Color Histograms, Hu Moments and Haralick Texture to classify Flower species using different Machine Learning classifiers available in scikit-learn.&source=webjeda" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >LinkedIn</a></li>
		</ul>
	</div>
</div>-->

		<div class="post-cover">
			<div class="carbon_advertisement">
				<div class="carbon_advertisement_wrapper">
					<script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CK7I623I&placement=gogul09githubio" id="_carbonads_js"></script>
				</div>
			</div>
			<article class="post">
				<div class="entry">
					<div class="git-showcase">
  <div>
    <a class="github-button" href="https://github.com/Gogul09" data-show-count="true" aria-label="Follow @Gogul09 on GitHub">Follow @Gogul09</a>
  </div>

  <div>
    <a class="github-button" href="https://github.com/Gogul09/image-classification-python/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork Gogul09/image-classification-python on GitHub">Fork</a>
  </div>

  <div>
    <a class="github-button" href="https://github.com/Gogul09/image-classification-python" data-icon="octicon-star" data-show-count="true" aria-label="Star Gogul09/image-classification-python on GitHub">Star</a>
  </div>  
</div>

<div class="sidebar_tracker" id="sidebar_tracker">
   <button onclick="closeSidebar('sidebar_tracker_content')">X</button>
   <p onclick="showSidebar('sidebar_tracker_content')">Contents</p>
   <ul id="sidebar_tracker_content">
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_1" href="#project-idea">Project Idea</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_2" href="#classification-problem">Classification Problem</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_3" href="#feature-extraction">Feature Extraction</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_4" href="#global-feature-descriptors">Global Feature Descriptors</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_5" href="#local-feature-descriptors">Local Feature Descriptors</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_6" href="#combining-global-features">Combining Global Features</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_7" href="#flowers-17-dataset">FLOWERS-17 dataset</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_8" href="#global-feature-extraction">Global Feature Extraction</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_9" href="#organizing-dataset">Organizing Dataset</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_10" href="#functions-for-global-feature-descriptors">Functions for global feature descriptors</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_11" href="#training-classifiers">Training classifiers</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_12" href="#testing-the-best-classifier">Testing the best classifier</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_13" href="#improving-classifier-accuracy">Improving classifier accuracy</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_14" href="#references">References</a></li>
  </ul>
</div>

<p><strong>The ability of a machine learning model to classify or label an image into its respective class with the help of learned features from hundreds of images is called as Image Classification.</strong></p>

<div class="note">
  <p><b>Note</b>: This tutorial is specific to <b>Windows</b> environment. Please modify code accordingly to work in other environments such as Linux and Max OS.</p>
</div>

<p>This is typically a supervised learning problem where we humans must provide training data (set of images along with its labels) to the machine learning model so that it learns how to discriminate each image (by learning the pattern behind each image) with respect to its label.</p>

<blockquote>
  <p><strong>Update (03/07/2019)</strong>: As Python2 faces <a href="https://pythonclock.org/" target="_blank">end of life</a>, the below code only supports <strong>Python3</strong>.</p>
</blockquote>

<p>In this post, we will look into one such image classification problem namely <strong>Flower Species Recognition</strong>, which is a hard problem because there are millions of flower species around the world. As we know machine learning is all about learning from past data, we need huge dataset of flower images to perform real-time flower species recognition. Without worrying too much on real-time flower recognition, we will learn how to perform a simple image classification task using computer vision and machine learning algorithms with the help of Python.</p>

<p>A short clip of what we will be making at the end of the tutorial üòä</p>

<figure>
    <img src="/images/software/plants-species/output.gif" />
    <figcaption style="text-align: center;">Flower Species Recognition - Watch the full video <a href="https://www.youtube.com/watch?v=_XHNPN1hzfk" target="_blank">here</a></figcaption>
</figure>

<div class="note">
<p><b>Update</b>: After reading this post, you could look into my <a href="https://gogul09.github.io/software/flower-recognition-deep-learning" target="_blank">post</a> on how to use state-of-the-art pretrained deep learning models such as Inception-V3, Xception, VGG16, VGG19, ResNet50, InceptionResNetv2 and MobileNet to this flower species recognition problem.</p>
</div>

<figure>
    <img src="/images/software/plants-species/garden.jpg" />
    <figcaption>Figure 1. Can we label each flower with it's name?<br />
        <span style="font-size: 9px">Image taken from <a href="http://www.artistic-law.com/garden-tag-beautiful-nature-day-water-park-hd-background-for-wallpapers-page-misc-desktop/colorful-garden-flowers-hd-free-wallpapers/" target="_blank">here</a></span>
    </figcaption>
</figure>

<h3 id="project-idea">Project Idea</h3>

<p>What if</p>

<ul>
  <li>You build an intelligent system that was trained with massive dataset of flower/plant images.</li>
  <li>Your system predicts the label/class of the flower/plant using Computer Vision techniques and Machine Learning algorithms.</li>
  <li>Your system searches the web for all the flower/plant related data after predicting the label/class of the captured image.</li>
  <li>Your system helps gardeners and farmers to increase their productivity and yield with the help of automating tasks in garden/farm.</li>
  <li>Your system applies the recent technological advancements such as Internet of Things (IoT) and Machine Learning in the agricultural domain.</li>
  <li>You build such a system for your home or your garden to monitor your plants using a Raspberry Pi.</li>
</ul>

<blockquote>
  <p>All the above scenarios need a common task to be done at the first place - <strong>Image Classification</strong>.</p>
</blockquote>

<p>Yeah! It is <strong>classifying</strong> a flower/plant into it‚Äôs corresponding class or category. For example, when our awesome intelligent assistant looks into a Sunflower image, it must label or classify it as a ‚ÄúSunflower‚Äù.</p>

<h3 id="classification-problem">Classification Problem</h3>
<p>Plant or Flower Species Classification is one of the most challenging and difficult problems in Computer Vision due to a variety of reasons.</p>

<p><b>Availability of plant/flower dataset</b><br />
Collecting plant/flower dataset is a time-consuming task. You can visit the <a href="#dataset">links</a> provided at the bottom of this post where I have collected all the publicly available plant/flower datasets around the world. Although traning a machine with these dataset might help in some scenerios, there are still more problems to be solved.</p>

<p><b>Millions of plant/flower species around the world</b><br />
This is something very interesting to look from a machine learning point of view. When I looked at the numbers in this <a href="https://www.currentresults.com/Environment-Facts/Plants-Animals/estimate-of-worlds-total-number-of-species.php" target="_blank">link</a>, I was frightened. Because, to accomodate every such species, we need to train our model with such large number of images with its labels. We are talking about 6 digit class labels here for which we need tremendous computing power (GPU farms).</p>

<p><b>High inter-class as well as intra-class variation</b><br />
What we mean here is that ‚ÄúSunflower‚Äù might be looking similar to a ‚ÄúDaffodil‚Äù in terms of color. This becomes an inter-class variation problem. Similarly, sometimes a single ‚ÄúSunflower‚Äù image might have differences within it‚Äôs class itself, which boils down to intra-class variation problem.</p>

<p><b>Fine-grained classification problem</b><br />
It means our model must not look into the image or video sequence and find <i>‚ÄúOh yes! there is a flower in this image‚Äù</i>. It means our model must tell <i>‚ÄúYeah! I found a flower in this image and I can tell you it‚Äôs a tulip‚Äù</i>.</p>

<p><b>Segmentation, View-point, Occlusion, Illumination and the list goes on..</b><br />
Segmenting the plant/flower region from an image is a challenging task. This is because we might need to remove the unwanted background and take only the foreground object (plant/flower) which is again a difficult thing due to the shape of plant/flower.</p>

<figure>
    <img src="https://farm5.staticflickr.com/4018/4651874181_2dbe64b3fb_b.jpg" />
    <figcaption>Figure 2. How will our model segment and classify flowers here?<br />
        <span style="font-size: 9px">Image taken from <a href="https://www.flickr.com/photos/fourseasonsgarden/4651874181" target="_blank">here</a></span>
    </figcaption>
</figure>

<h3 id="feature-extraction">Feature Extraction</h3>

<p>Features are the information or list of numbers that are extracted from an image. These are real-valued numbers (integers, float or binary). There are a wider range of feature extraction algorithms in Computer Vision.</p>

<p>When deciding about the features that could quantify plants and flowers, we could possibly think of <span class="light">Color, Texture</span> and <span class="light">Shape</span> as the primary ones. This is an obvious choice to globally quantify and represent the plant or flower image.</p>

<p>But this approach is less likely to produce good results, if we choose only one feature vector, as these species have many attributes in common like <strong>sunflower</strong> will be similar to <strong>daffodil</strong> in terms of color and so on. So, we need to quantify the image by combining different feature descriptors so that it describes the image more <strong>effectively</strong>.</p>

<figure>
    <img src="/images/software/plants-species/feature_extraction.jpg" />
    <figcaption>Figure 3. Feature Extraction</figcaption>
</figure>

<h3 id="global-feature-descriptors">Global Feature Descriptors</h3>

<p>These are the feature descriptors that quantifies an image globally. These don‚Äôt have the concept of <a href="https://en.wikipedia.org/wiki/Interest_point_detection" target="_blank">interest points</a> and thus, takes in the entire image for processing. Some of the commonly used global feature descriptors are</p>
<ul>
  <li><strong>Color</strong>   - Color Channel Statistics (Mean, Standard Deviation) and <a href="https://en.wikipedia.org/wiki/Color_histogram" target="_blank">Color Histogram</a></li>
  <li><strong>Shape</strong>   - <a href="https://en.wikipedia.org/wiki/Image_moment" target="_blank">Hu Moments</a>, <a href="https://en.wikipedia.org/wiki/Zernike_polynomials" target="_blank">Zernike Moments</a></li>
  <li><strong>Texture</strong> - <a href="http://haralick.org/journals/TexturalFeatures.pdf" target="_blank">Haralick Texture</a>, <a href="https://en.wikipedia.org/wiki/Local_binary_patterns" target="_blank">Local Binary Patterns</a> (LBP)</li>
  <li><strong>Others</strong>  - <a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" target="_blank">Histogram of Oriented Gradients</a> (HOG), Threshold Adjancency Statistics (TAS)</li>
</ul>

<h3 id="local-feature-descriptors">Local Feature Descriptors</h3>

<p>These are the feature descriptors that quantifies local regions of an image. Interest points are determined in the entire image and image patches/regions surrounding those interest points are considered for analysis. Some of the commonly used local feature descriptors are</p>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform" target="_blank">SIFT</a> (Scale Invariant Feature Transform)</li>
  <li><a href="https://en.wikipedia.org/wiki/Speeded_up_robust_features" target="_blank">SURF</a> (Speeded Up Robust Features)</li>
  <li><a href="https://en.wikipedia.org/wiki/Oriented_FAST_and_rotated_BRIEF" target="_blank">ORB</a> (Oriented Fast and Rotated BRIEF)</li>
  <li><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_brief/py_brief.html" target="_blank">BRIEF</a> (Binary Robust Independed Elementary Features)</li>
</ul>

<h3 id="combining-global-features">Combining Global Features</h3>

<p>There are two popular ways to combine these feature vectors.</p>
<ul>
  <li>For global feature vectors, we just concatenate each feature vector to form a single global feature vector. This is the approach we will be using in this tutorial.</li>
  <li>For local feature vectors as well as combination of global and local feature vectors, we need something called as <a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision" target="_blank">Bag of Visual Words</a> (BOVW). This approach is not discussed in this tutorial, but there are lots of resources to learn this technique. Normally, it uses Vocabulory builder, K-Means clustering, Linear SVM, and Td-Idf vectorization.</li>
</ul>

<figure>
    <img src="/images/software/plants-species/global_features.jpg" />
    <figcaption>Figure 4. Global Features to quantify a flower image.</figcaption>
</figure>

<h3 id="flowers-17-dataset">FLOWERS-17 dataset</h3>

<p>We will use the FLOWER17 dataset provided by the University of Oxford, Visual Geometry group. This dataset is a highly challenging dataset with 17 classes of flower species, each having 80 images. So, totally we have 1360 images to train our model. For more information about the dataset and to download it, kindly visit <a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/17/" target="_blank">this</a> link.</p>

<figure>
    <img src="/images/software/plants-species/flowers17_data.jpg" />
    <figcaption>Figure 5. FLOWER17 dataset from the University of Oxford, Visual Geometry group</figcaption>
</figure>

<h3 id="organizing-dataset">Organizing Dataset</h3>

<p>The folder structure for this example is given below.</p>

<h3 class="code-head">folder structure</h3>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre>|--image-classification <span class="o">(</span>folder<span class="o">)</span>
|--|--dataset <span class="o">(</span>folder<span class="o">)</span>
|--|--|--train <span class="o">(</span>folder<span class="o">)</span>
|--|--|--|--cowbell <span class="o">(</span>folder<span class="o">)</span>
|--|--|--|--|--image_1.jpg
|--|--|--|--|--image_2.jpg
|--|--|--|--|--...
|--|--|--|--tulip <span class="o">(</span>folder<span class="o">)</span>
|--|--|--|--|--image_1.jpg
|--|--|--|--|--image_2.jpg
|--|--|--|--|--...
|--|--|--test <span class="o">(</span>folder<span class="o">)</span>
|--|--|--|--image_1.jpg
|--|--|--|--image_2.jpg
|--|--output <span class="o">(</span>folder<span class="o">)</span>
|--|--|--data.h5
|--|--|--labels.h5
|--|--global.py
|--|--train_test.py

</pre></td></tr></tbody></table></code></pre></div></div>

<div class="note">
<p><b>Update (03/07/2019):</b> To create the above folder structure and organize the training dataset folder, I have created a script for you - <a href="https://github.com/Gogul09/image-classification-python/blob/master/organize_flowers17.py" target="_blank">organize_flowers17.py</a>. Please use this script first before calling any other script in this tutorial.</p>
</div>

<h3 class="code-head">organize_flowers17.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
</pre></td><td class="rouge-code"><pre><span class="c1">#-----------------------------------------
# DOWNLOAD AND ORGANIZE FLOWERS17 DATASET
#-----------------------------------------
</span><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">tarfile</span>
<span class="kn">import</span> <span class="n">urllib.request</span>

<span class="k">def</span> <span class="nf">download_dataset</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">work_dir</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] Downloading flowers17 dataset</span><span class="gp">...</span><span class="p">.</span><span class="sh">"</span><span class="s">)
    filename, _ = urllib.request.urlretrieve(url + filename, filename)
    statinfo = os.stat(filename)
    print(</span><span class="sh">"</span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Succesfully</span> <span class="n">downloaded</span> <span class="sh">"</span><span class="s"> + filename + </span><span class="sh">"</span> <span class="sh">"</span><span class="s"> + str(statinfo.st_size) + </span><span class="sh">"</span> <span class="nb">bytes</span><span class="p">.</span><span class="sh">"</span><span class="s">)
    untar(filename, work_dir)

def jpg_files(members):
  for tarinfo in members:
    if os.path.splitext(tarinfo.name)[1] == </span><span class="sh">"</span><span class="p">.</span><span class="n">jpg</span><span class="sh">"</span><span class="s">:
      yield tarinfo

def untar(fname, path):
  tar = tarfile.open(fname)
  tar.extractall(path=path, members=jpg_files(tar))
  tar.close()
  print(</span><span class="sh">"</span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Dataset</span> <span class="n">extracted</span> <span class="n">successfully</span><span class="p">.</span><span class="sh">"</span><span class="s">)

#-------------------------
# MAIN FUNCTION
#-------------------------
if __name__ == </span><span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="s">:
  flowers17_url  = </span><span class="sh">"</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">robots</span><span class="p">.</span><span class="n">ox</span><span class="p">.</span><span class="n">ac</span><span class="p">.</span><span class="n">uk</span><span class="o">/~</span><span class="n">vgg</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">flowers</span><span class="o">/</span><span class="mi">17</span><span class="o">/</span><span class="sh">"</span><span class="s">
  flowers17_name = </span><span class="sh">"</span><span class="mi">17</span><span class="n">flowers</span><span class="p">.</span><span class="n">tgz</span><span class="sh">"</span><span class="s">
  train_dir      = </span><span class="sh">"</span><span class="n">dataset</span><span class="sh">"</span><span class="s">

  if not os.path.exists(train_dir):
    os.makedirs(train_dir)

  download_dataset(flowers17_name, flowers17_url, train_dir)
  if os.path.exists(train_dir + </span><span class="sh">"</span>\\<span class="n">jpg</span><span class="sh">"</span><span class="s">):
    os.rename(train_dir + </span><span class="sh">"</span>\\<span class="n">jpg</span><span class="sh">"</span><span class="s">, train_dir + </span><span class="sh">"</span>\\<span class="n">train</span><span class="sh">"</span><span class="s">)


  # get the class label limit
  class_limit = 17

  # take all the images from the dataset
  image_paths = glob.glob(train_dir + </span><span class="sh">"</span>\\<span class="n">train</span>\\<span class="o">*</span><span class="p">.</span><span class="n">jpg</span><span class="sh">"</span><span class="s">)

  # variables to keep track
  label = 0
  i = 0
  j = 80

  # flower17 class names
  class_names = [</span><span class="sh">"</span><span class="n">daffodil</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">snowdrop</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">lilyvalley</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">bluebell</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">crocus</span><span class="sh">"</span><span class="s">,
             </span><span class="sh">"</span><span class="n">iris</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">tigerlily</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">tulip</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">fritillary</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">sunflower</span><span class="sh">"</span><span class="s">, 
             </span><span class="sh">"</span><span class="n">daisy</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">coltsfoot</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">dandelion</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">cowslip</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">buttercup</span><span class="sh">"</span><span class="s">,
             </span><span class="sh">"</span><span class="n">windflower</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="n">pansy</span><span class="sh">"</span><span class="s">]

  # loop over the class labels
  for x in range(1, class_limit+1):
    # create a folder for that class
    os.makedirs(train_dir + </span><span class="sh">"</span>\\<span class="n">train</span>\\<span class="sh">"</span><span class="s"> + class_names[label])
    
    # get the current path
    cur_path = train_dir + </span><span class="sh">"</span>\\<span class="n">train</span>\\<span class="sh">"</span><span class="s"> + class_names[label] + </span><span class="sh">"</span>\\<span class="sh">"</span><span class="s">
    
    # loop over the images in the dataset
    for index, image_path in enumerate(image_paths[i:j], start=1):
      original_path   = image_path
      image_path      = image_path.split(</span><span class="sh">"</span>\\<span class="sh">"</span><span class="s">)
      image_file_name = str(index) + </span><span class="sh">"</span><span class="p">.</span><span class="n">jpg</span><span class="sh">"</span><span class="s">
      os.rename(original_path, cur_path + image_file_name)
    
    i += 80
    j += 80
    label += 1
</span></pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="global-feature-extraction">Global Feature Extraction</h3>

<p>Ok! It‚Äôs time to code!</p>

<p>We will use a simpler approach to produce a baseline accuracy for our problem. It means everything should work somehow without any error.</p>

<p>Our three global feature descriptors are</p>
<ol>
  <li><strong>Color Histogram</strong> that quantifies <strong>color</strong> of the flower.</li>
  <li><strong>Hu Moments</strong> that quantifies <strong>shape</strong> of the flower.</li>
  <li><strong>Haralick Texture</strong> that quantifies <strong>texture</strong> of the flower.</li>
</ol>

<p>As you might know images are matrices, we need an efficient way to store our feature vectors locally. Our script takes one image at a time, extract three global features, concatenates the three global features into a single global feature and saves it along with its label in a <a href="https://en.wikipedia.org/wiki/Hierarchical_Data_Format" target="_blank">HDF5 file format</a>.</p>

<p>Insted of using HDF5 file-format, we could use ‚Äú.csv‚Äù file-format to store the features. But, as we will be working with large amounts of data in future, becoming familiar with HDF5 format is worth it.</p>

<h3 class="code-head">global.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="c1">#-----------------------------------
# GLOBAL FEATURE EXTRACTION
#-----------------------------------
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">mahotas</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">h5py</span>

<span class="c1">#--------------------
# tunable-parameters
#--------------------
</span><span class="n">images_per_class</span> <span class="o">=</span> <span class="mi">80</span>
<span class="n">fixed_size</span>       <span class="o">=</span> <span class="nf">tuple</span><span class="p">((</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
<span class="n">train_path</span>       <span class="o">=</span> <span class="sh">"</span><span class="s">dataset/train</span><span class="sh">"</span>
<span class="n">h5_data</span>          <span class="o">=</span> <span class="sh">'</span><span class="s">output/data.h5</span><span class="sh">'</span>
<span class="n">h5_labels</span>        <span class="o">=</span> <span class="sh">'</span><span class="s">output/labels.h5</span><span class="sh">'</span>
<span class="n">bins</span>             <span class="o">=</span> <span class="mi">8</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li>Lines 4 - 10 imports the necessary libraries we need to work with.</li>
  <li>Line 16 used to convert the input image to a fixed size of (500, 500).</li>
  <li>Line 17 is the path to our training dataset.</li>
  <li>Lines 18 - 19 stores our global features and labels in <span class="coding">output</span> directory.</li>
  <li>Line 20 is the number of bins for color histograms.</li>
</ul>

<h3 id="functions-for-global-feature-descriptors">Functions for global feature descriptors</h3>

<h4 id="1-hu-moments">1. Hu Moments</h4>
<p>To extract Hu Moments features from the image, we use <span class="coding">cv2.HuMoments()</span> function provided by OpenCV. The argument to this function is the moments of the image <span class="coding">cv2.moments()</span> flatenned. It means we compute the moments of the image and convert it to a vector using <span class="coding">flatten()</span>. Before doing that, we convert our color image into a grayscale image as moments expect images to be grayscale.</p>

<h3 class="code-head">global.py<span>code</span></h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1"># feature-descriptor-1: Hu Moments
</span><span class="k">def</span> <span class="nf">fd_hu_moments</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
    <span class="n">feature</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">HuMoments</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="nf">moments</span><span class="p">(</span><span class="n">image</span><span class="p">)).</span><span class="nf">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">feature</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="2-haralick-textures">2. Haralick Textures</h4>
<p>To extract Haralick Texture features from the image, we make use of mahotas library. The function we will be using is <span class="coding">mahotas.features.haralick()</span>. Before doing that, we convert our color image into a grayscale image as haralick feature descriptor expect images to be grayscale.</p>

<h3 class="code-head">global.py<span>code</span></h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="c1"># feature-descriptor-2: Haralick Texture
</span><span class="k">def</span> <span class="nf">fd_haralick</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="c1"># convert the image to grayscale
</span>    <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
    <span class="c1"># compute the haralick texture feature vector
</span>    <span class="n">haralick</span> <span class="o">=</span> <span class="n">mahotas</span><span class="p">.</span><span class="n">features</span><span class="p">.</span><span class="nf">haralick</span><span class="p">(</span><span class="n">gray</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># return the result
</span>    <span class="k">return</span> <span class="n">haralick</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="3-color-histogram">3. Color Histogram</h4>
<p>To extract Color Histogram features from the image, we use <span class="coding">cv2.calcHist()</span> function provided by <a href="https://docs.opencv.org/3.2.0/d1/db7/tutorial_py_histogram_begins.html" target="_blank">OpenCV</a>. The arguments it expects are the image, channels, mask, histSize (bins) and ranges for each channel [typically 0-256). We then normalize the histogram using <span class="coding">normalize()</span> function of OpenCV and return a flattened version of this normalized matrix using <span class="coding">flatten()</span>.</p>

<h3 class="code-head">global.py<span>code</span></h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="c1"># feature-descriptor-3: Color Histogram
</span><span class="k">def</span> <span class="nf">fd_histogram</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># convert the image to HSV color-space
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2HSV</span><span class="p">)</span>
    <span class="c1"># compute the color histogram
</span>    <span class="n">hist</span>  <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">calcHist</span><span class="p">([</span><span class="n">image</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="n">bins</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">bins</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
    <span class="c1"># normalize the histogram
</span>    <span class="n">cv2</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">hist</span><span class="p">,</span> <span class="n">hist</span><span class="p">)</span>
    <span class="c1"># return the histogram
</span>    <span class="k">return</span> <span class="n">hist</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="note"><p>
<b>Important</b>: To get the list of training labels associated with each image, under our training path, we are supposed to have folders that are named with the labels of the respective flower species name inside which all the images belonging to that label are kept. Please keep a note of this as you might get errors if you don't have a proper folder structure. 
</p>
</div>

<h3 class="code-head">global.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="c1"># get the training labels
</span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>

<span class="c1"># sort the training labels
</span><span class="n">train_labels</span><span class="p">.</span><span class="nf">sort</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># empty lists to hold feature vectors and labels
</span><span class="n">global_features</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span>          <span class="o">=</span> <span class="p">[]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>['bluebell', 'buttercup', 'coltsfoot', 'cowslip', 'crocus', 'daffodil', 'daisy', 'dandelion', 'fritillary', 'iris', 'lilyvalley', 'pansy', 'snowdrop', 'sunflower', 'tigerlily', 'tulip', 'windflower']
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For each of the training label name, we iterate through the corresponding folder to get all the images inside it. For each image that we iterate, we first resize the image into a fixed size. Then, we extract the three global features and concatenate these three features using NumPy‚Äôs <span class="coding">np.hstack()</span> function. We keep track of the feature with its label using those two lists we created above - <span class="coding">labels</span> and <span class="coding">global_features</span>. You could even use a dictionary here. Below is the code snippet to do these.</p>

<h3 class="code-head">global.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre><span class="c1"># loop over the training data sub-folders
</span><span class="k">for</span> <span class="n">training_name</span> <span class="ow">in</span> <span class="n">train_labels</span><span class="p">:</span>
    <span class="c1"># join the training data path and each species training folder
</span>    <span class="nb">dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">training_name</span><span class="p">)</span>

    <span class="c1"># get the current training label
</span>    <span class="n">current_label</span> <span class="o">=</span> <span class="n">training_name</span>

    <span class="c1"># loop over the images in each sub-folder
</span>    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">images_per_class</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># get the image file name
</span>        <span class="nb">file</span> <span class="o">=</span> <span class="nb">dir</span> <span class="o">+</span> <span class="sh">"</span><span class="s">/</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s">.jpg</span><span class="sh">"</span>

        <span class="c1"># read the image and resize it to a fixed-size
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">fixed_size</span><span class="p">)</span>

        <span class="c1">####################################
</span>        <span class="c1"># Global Feature extraction
</span>        <span class="c1">####################################
</span>        <span class="n">fv_hu_moments</span> <span class="o">=</span> <span class="nf">fd_hu_moments</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">fv_haralick</span>   <span class="o">=</span> <span class="nf">fd_haralick</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">fv_histogram</span>  <span class="o">=</span> <span class="nf">fd_histogram</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1">###################################
</span>        <span class="c1"># Concatenate global features
</span>        <span class="c1">###################################
</span>        <span class="n">global_feature</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">([</span><span class="n">fv_histogram</span><span class="p">,</span> <span class="n">fv_haralick</span><span class="p">,</span> <span class="n">fv_hu_moments</span><span class="p">])</span>

        <span class="c1"># update the list of labels and feature vectors
</span>        <span class="n">labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">current_label</span><span class="p">)</span>
        <span class="n">global_features</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">global_feature</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] processed folder: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">current_label</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] completed Global Feature Extraction</span><span class="gp">...</span><span class="sh">"</span><span class="s">)
</span></pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre>[STATUS] processed folder: bluebell
[STATUS] processed folder: buttercup
[STATUS] processed folder: coltsfoot
[STATUS] processed folder: cowslip
[STATUS] processed folder: crocus
[STATUS] processed folder: daffodil
[STATUS] processed folder: daisy
[STATUS] processed folder: dandelion
[STATUS] processed folder: fritillary
[STATUS] processed folder: iris
[STATUS] processed folder: lilyvalley
[STATUS] processed folder: pansy
[STATUS] processed folder: snowdrop
[STATUS] processed folder: sunflower
[STATUS] processed folder: tigerlily
[STATUS] processed folder: tulip
[STATUS] processed folder: windflower
[STATUS] completed Global Feature Extraction...
</pre></td></tr></tbody></table></code></pre></div></div>

<p>After extracting features and concatenating it, we need to save this data locally. Before saving this data, we use something called <span class="coding">LabelEncoder()</span> to encode our labels in a proper format. This is to make sure that the labels are represented as unique numbers. As we have used different global features, one feature might dominate the other with respect to it‚Äôs value. In such scenarios, it is better to normalize everything within a range (say 0-1). Thus, we normalize the features using scikit-learn‚Äôs <span class="coding">MinMaxScaler()</span> function. After doing these two steps, we use h5py to save our features and labels locally in <span class="coding">.h5</span> file format. Below is the code snippet to do these.</p>

<h3 class="code-head">global.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td class="rouge-code"><pre><span class="c1"># get the overall feature vector size
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] feature vector size {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">global_features</span><span class="p">).</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># get the overall training label size
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] training Labels {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># encode the target labels
</span><span class="n">targetNames</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">le</span>          <span class="o">=</span> <span class="nc">LabelEncoder</span><span class="p">()</span>
<span class="n">target</span>      <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] training labels encoded</span><span class="gp">...</span><span class="sh">"</span><span class="s">)

# scale features in the range (0-1)
scaler            = MinMaxScaler(feature_range=(0, 1))
rescaled_features = scaler.fit_transform(global_features)
print(</span><span class="sh">"</span><span class="p">[</span><span class="n">STATUS</span><span class="p">]</span> <span class="n">feature</span> <span class="n">vector</span> <span class="n">normalized</span><span class="p">...</span><span class="sh">"</span><span class="s">)

print(</span><span class="sh">"</span><span class="p">[</span><span class="n">STATUS</span><span class="p">]</span> <span class="n">target</span> <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(target))
print(</span><span class="sh">"</span><span class="p">[</span><span class="n">STATUS</span><span class="p">]</span> <span class="n">target</span> <span class="n">labels</span> <span class="n">shape</span><span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(target.shape))

# save the feature vector using HDF5
h5f_data = h5py.File(h5_data, </span><span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="s">)
h5f_data.create_dataset(</span><span class="sh">'</span><span class="s">dataset_1</span><span class="sh">'</span><span class="s">, data=np.array(rescaled_features))

h5f_label = h5py.File(h5_labels, </span><span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="s">)
h5f_label.create_dataset(</span><span class="sh">'</span><span class="s">dataset_1</span><span class="sh">'</span><span class="s">, data=np.array(target))

h5f_data.close()
h5f_label.close()

print(</span><span class="sh">"</span><span class="p">[</span><span class="n">STATUS</span><span class="p">]</span> <span class="n">end</span> <span class="n">of</span> <span class="n">training</span><span class="p">..</span><span class="sh">"</span><span class="s">)
</span></pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>[STATUS] feature vector size (1360, 532)
[STATUS] training Labels (1360,)
[STATUS] training labels encoded...
[STATUS] feature vector normalized...
[STATUS] target labels: [ 0  0  0 ..., 16 16 16]
[STATUS] target labels shape: (1360,)
[STATUS] end of training..
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Notice that there are 532 columns in the global feature vector which tells us that when we concatenate color histogram, haralick texture and hu moments, we get a single row with 532 columns. So, for 1360 images, we get a feature vector of size (1360, 532). Also, you could see that the target labels are encoded as integer values in the range (0-16) denoting the 17 classes of flower species.</p>

<h3 id="training-classifiers">Training classifiers</h3>

<p>After extracting, concatenating and saving global features and labels from our training dataset, it‚Äôs time to train our system. To do that, we need to create our Machine Learning models. For creating our machine learning model‚Äôs, we take the help of <a href="http://scikit-learn.org/" target="_blank">scikit-learn</a>.</p>

<p>We will choose Logistic Regression, Linear Discriminant Analysis, K-Nearest Neighbors, Decision Trees, Random Forests, Gaussian Naive Bayes and Support Vector Machine as our machine learning models. To understand these algorithms, please go through Professor Andrew NG‚Äôs amazing Machine Learning <a href="https://www.coursera.org/learn/machine-learning" target="_blank">course</a> at Coursera or you could look into this awesome <a href="https://www.youtube.com/playlist?list=PLea0WJq13cnCS4LLMeUuZmTxqsqlhwUoe">playlist</a> of Dr.Noureddin Sadawi.</p>

<p>Furthermore, we will use <span class="coding">train_test_split</span> function provided by <span class="coding">scikit-learn</span> to split our training dataset into train_data and test_data. By this way, we train the models with the train_data and test the trained model with the unseen test_data. The split size is decided by the <span class="coding">test_size</span> parameter.</p>

<p>We will also use a technique called <a href="https://www.youtube.com/watch?v=TIgfjmp-4BA" target="_blank">K-Fold Cross Validation</a>, a model-validation technique which is the best way to predict ML model‚Äôs accuracy. In short, if we choose K = 10, then we split the entire data into 9 parts for training and 1 part for testing uniquely over each round upto 10 times. To understand more about this, go through <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" target="_blank">this link</a>.</p>

<p>We import all the necessary libraries to work with and create a <span class="coding">models</span> list. This list will have all our machine learning models that will get trained with our locally stored features. During import of our features from the locally saved <span class="coding">.h5</span> file-format, it is always a good practice to check its shape. To do that, we make use of <span class="coding">np.array()</span> function to convert the <span class="coding">.h5</span> data into a numpy array and then print its shape.</p>

<h3 class="code-head">train_test.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
</pre></td><td class="rouge-code"><pre><span class="c1">#-----------------------------------
# TRAINING OUR MODEL
#-----------------------------------
</span><span class="kn">import</span> <span class="n">h5py</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>
<span class="kn">from</span> <span class="n">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="n">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>

<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">#--------------------
# tunable-parameters
#--------------------
</span><span class="n">num_trees</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.10</span>
<span class="n">seed</span>      <span class="o">=</span> <span class="mi">9</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">dataset/train</span><span class="sh">"</span>
<span class="n">test_path</span>  <span class="o">=</span> <span class="sh">"</span><span class="s">dataset/test</span><span class="sh">"</span>
<span class="n">h5_data</span>    <span class="o">=</span> <span class="sh">'</span><span class="s">output/data.h5</span><span class="sh">'</span>
<span class="n">h5_labels</span>  <span class="o">=</span> <span class="sh">'</span><span class="s">output/labels.h5</span><span class="sh">'</span>
<span class="n">scoring</span>    <span class="o">=</span> <span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span>

<span class="c1"># get the training labels
</span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>

<span class="c1"># sort the training labels
</span><span class="n">train_labels</span><span class="p">.</span><span class="nf">sort</span><span class="p">()</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">test_path</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="n">test_path</span><span class="p">)</span>

<span class="c1"># create all the machine learning models
</span><span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">LR</span><span class="sh">'</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">LDA</span><span class="sh">'</span><span class="p">,</span> <span class="nc">LinearDiscriminantAnalysis</span><span class="p">()))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">KNN</span><span class="sh">'</span><span class="p">,</span> <span class="nc">KNeighborsClassifier</span><span class="p">()))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">CART</span><span class="sh">'</span><span class="p">,</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">RF</span><span class="sh">'</span><span class="p">,</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">num_trees</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">NB</span><span class="sh">'</span><span class="p">,</span> <span class="nc">GaussianNB</span><span class="p">()))</span>
<span class="n">models</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="sh">'</span><span class="s">SVM</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)))</span>

<span class="c1"># variables to hold the results and names
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">names</span>   <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># import the feature vector and trained labels
</span><span class="n">h5f_data</span>  <span class="o">=</span> <span class="n">h5py</span><span class="p">.</span><span class="nc">File</span><span class="p">(</span><span class="n">h5_data</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span>
<span class="n">h5f_label</span> <span class="o">=</span> <span class="n">h5py</span><span class="p">.</span><span class="nc">File</span><span class="p">(</span><span class="n">h5_labels</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span>

<span class="n">global_features_string</span> <span class="o">=</span> <span class="n">h5f_data</span><span class="p">[</span><span class="sh">'</span><span class="s">dataset_1</span><span class="sh">'</span><span class="p">]</span>
<span class="n">global_labels_string</span>   <span class="o">=</span> <span class="n">h5f_label</span><span class="p">[</span><span class="sh">'</span><span class="s">dataset_1</span><span class="sh">'</span><span class="p">]</span>

<span class="n">global_features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">global_features_string</span><span class="p">)</span>
<span class="n">global_labels</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">global_labels_string</span><span class="p">)</span>

<span class="n">h5f_data</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
<span class="n">h5f_label</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

<span class="c1"># verify the shape of the feature vector and labels
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] features shape: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">global_features</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] labels shape: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">global_labels</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] training started</span><span class="gp">...</span><span class="sh">"</span><span class="s">)
</span></pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre>[STATUS] features shape: (1360, 532)
[STATUS] labels shape: (1360,)
[STATUS] training started...
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As I already mentioned, we will be splitting our training dataset into train_data as well as test_data. <span class="coding">train_test_split()</span> function does that for us and it returns four variables as shown below.</p>

<h3 class="code-head">train_test.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># split the training and testing data
</span><span class="p">(</span><span class="n">trainDataGlobal</span><span class="p">,</span> <span class="n">testDataGlobal</span><span class="p">,</span> <span class="n">trainLabelsGlobal</span><span class="p">,</span> <span class="n">testLabelsGlobal</span><span class="p">)</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">global_features</span><span class="p">),</span>
                                                                                          <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">global_labels</span><span class="p">),</span>
                                                                                          <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
                                                                                          <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[STATUS] splitted train and test data</span><span class="gp">...</span><span class="sh">"</span><span class="s">)
print(</span><span class="sh">"</span><span class="n">Train</span> <span class="n">data</span>  <span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(trainDataGlobal.shape))
print(</span><span class="sh">"</span><span class="n">Test</span> <span class="n">data</span>   <span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(testDataGlobal.shape))
print(</span><span class="sh">"</span><span class="n">Train</span> <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(trainLabelsGlobal.shape))
print(</span><span class="sh">"</span><span class="n">Test</span> <span class="n">labels</span> <span class="p">:</span> <span class="p">{}</span><span class="sh">"</span><span class="s">.format(testLabelsGlobal.shape))
</span></pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>[STATUS] splitted train and test data...
Train data  : (1224, 532)
Test data   : (136, 532)
Train labels: (1224,)
Test labels : (136,)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Notice we have decent amount of train_data and less test_data. We always want to train our model with more data so that our model generalizes well. So, we keep <span class="coding">test_size</span> variable to be in the range (0.10 - 0.30). Not more than that.</p>

<p>Finally, we train each of our machine learning model and check the cross-validation results. Here, we have used only our train_data.</p>

<h3 class="code-head">train_test.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="c1"># 10-fold cross validation
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">kfold</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">trainDataGlobal</span><span class="p">,</span> <span class="n">trainLabelsGlobal</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>
    <span class="n">names</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="sh">"</span><span class="s">%s: %f (%f)</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">cv_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">cv_results</span><span class="p">.</span><span class="nf">std</span><span class="p">())</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

<span class="c1"># boxplot algorithm comparison
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">pyplot</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Machine Learning algorithm comparison</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xticklabels</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre>LR:   0.501719 (0.051735)
LDA:  0.441197 (0.034820)
KNN:  0.362742 (0.025958)
CART: 0.474690 (0.041314)
RF:   0.643809 (0.029491)
NB:   0.361102 (0.034966)
SVM:  0.043343 (0.027239)
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
    <img src="/images/software/plants-species/classification.png" />
    <figcaption>Figure 6. Comparison chart of different machine learning classifiers used (Y-axis: Accuracy)</figcaption>
</figure>

<p>As you can see, the accuracies are <strong>not</strong> so good. Random Forests (RF) gives the maximum accuracy of <strong>64.38%</strong>. This is mainly due to the number of images we use per class. We need large amounts of data to get better accuracy. For example, for a single class, we atleast need around 500-1000 images which is indeed a time-consuming task. But, in this post, I have provided you with the steps, tools and concepts needed to solve an image classification problem.</p>

<h3 id="testing-the-best-classifier">Testing the best classifier</h3>

<p>Let‚Äôs quickly try to build a Random Forest model, train it with the training data and test it on some unseen flower images.</p>

<h3 class="code-head">train_test.py<span>code</span></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre></td><td class="rouge-code"><pre><span class="c1">#-----------------------------------
# TESTING OUR MODEL
#-----------------------------------
</span>
<span class="c1"># to visualize results
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># create the model - Random Forests
</span><span class="n">clf</span>  <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">num_trees</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># fit the training data to the model
</span><span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">trainDataGlobal</span><span class="p">,</span> <span class="n">trainLabelsGlobal</span><span class="p">)</span>

<span class="c1"># loop through the test images
</span><span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">glob</span><span class="p">.</span><span class="nf">glob</span><span class="p">(</span><span class="n">test_path</span> <span class="o">+</span> <span class="sh">"</span><span class="s">/*.jpg</span><span class="sh">"</span><span class="p">):</span>
    <span class="c1"># read the image
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

    <span class="c1"># resize the image
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">fixed_size</span><span class="p">)</span>

    <span class="c1">####################################
</span>    <span class="c1"># Global Feature extraction
</span>    <span class="c1">####################################
</span>    <span class="n">fv_hu_moments</span> <span class="o">=</span> <span class="nf">fd_hu_moments</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">fv_haralick</span>   <span class="o">=</span> <span class="nf">fd_haralick</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">fv_histogram</span>  <span class="o">=</span> <span class="nf">fd_histogram</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="c1">###################################
</span>    <span class="c1"># Concatenate global features
</span>    <span class="c1">###################################
</span>    <span class="n">global_feature</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">([</span><span class="n">fv_histogram</span><span class="p">,</span> <span class="n">fv_haralick</span><span class="p">,</span> <span class="n">fv_hu_moments</span><span class="p">])</span>

    <span class="c1"># scale features in the range (0-1)
</span>    <span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">rescaled_feature</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">global_feature</span><span class="p">)</span>

    <span class="c1"># predict label of test image
</span>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">rescaled_feature</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># show predicted label on image
</span>    <span class="n">cv2</span><span class="p">.</span><span class="nf">putText</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">prediction</span><span class="p">],</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">cv2</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># display the output image
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
    <img src="/images/software/plants-species/result1.png" />
    <figcaption>Figure 7. Prediction 1 - Sunflower (Correct)</figcaption>
</figure>

<figure>
    <img src="/images/software/plants-species/result2.png" />
    <figcaption>Figure 8. Prediction 2 - Bluebell (Correct)</figcaption>
</figure>

<figure>
    <img src="/images/software/plants-species/result3.png" />
    <figcaption>Figure 9. Prediction 3 - Pansy (Correct)</figcaption>
</figure>

<figure>
    <img src="/images/software/plants-species/result4.png" />
    <figcaption>Figure 10. Prediction 4 - Buttercup (Wrong)</figcaption>
</figure>

<p>As we can see, our approach seems to do pretty good at recognizing flowers. But it also predicted wrong label like the <strong>last one</strong>. Instead of sunflower, our model predicted buttercup.</p>

<p>You can download the entire code used in this post <a href="https://github.com/Gogul09/image-classification-python" target="_blank">here</a>.</p>

<h3 id="improving-classifier-accuracy">Improving classifier accuracy</h3>

<p>So, how are we going to improve the accuracy further? Fortunately, there are multiple techniques to achieve better accuracy. Some of them are listed below.</p>

<ol>
  <li>Gather more data for each class. (500-1000) images per class.</li>
  <li>Use Data Augmentation to generate more images per class.</li>
  <li>Global features along with local features such as SIFT, SURF or DENSE could be used along with Bag of Visual Words (BOVW) technique.</li>
  <li>Local features alone could be tested with BOVW technique.</li>
  <li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank">Convolutional Neural Networks</a> - State-of-the-art models when it comes to Image Classification and Object Recognition.</li>
</ol>

<p>Some of the state-of-the-art Deep Learning CNN models are mentioned below.</p>

<ul>
  <li>AlexNet</li>
  <li>Inception-V3</li>
  <li>Xception</li>
  <li>VGG16</li>
  <li>VGG19</li>
  <li>OverFeat</li>
  <li>ZeilerNet</li>
  <li>MSRA</li>
</ul>

<p>But to apply CNN to this problem, the size of our dataset must be large enough and also to process those tremendous amount of data it is always recommended to use GPUs.</p>

<div class="references">
<h3 id="references">References</h3>

<h5>Research Papers</h5>

<ul>
  <li><a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback06.pdf" target="_blank">A Visual Vocabulary for Flower Classification</a></li>
  <li><a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback07.pdf" target="_blank">Delving into the whorl of flower segmentation</a></li>
  <li><a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf" target="_blank">Automated flower classification over a large number of classes</a></li>
  <li><a href="http://ceur-ws.org/Vol-1180/CLEF2014wn-Life-SunderhaufEt2014.pdf" target="_blank">Fine-Grained Plant Classification Using Convolutional Neural Networks for Feature Extraction</a></li>
  <li><a href="http://ceur-ws.org/Vol-1391/121-CR.pdf" target="_blank">Fine-tuning Deep Convolutional Networks for Plant Recognition</a></li>
  <li><a href="http://www.sciencedirect.com/science/article/pii/S1537511016301465" target="_blank">Plant species classification using deep convolutional neural network</a></li>
  <li><a href="http://ieeexplore.ieee.org/document/7577698/" target="_blank">Plant classification using convolutional neural networks</a></li>
  <li><a href="http://ieeexplore.ieee.org/document/7350839/" target="_blank">Deep-plant: Plant identification with convolutional neural networks</a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4934169/" target="_blank">Deep Neural Networks Based Recognition of Plant Diseases by Leaf Image Classification</a></li>
  <li><a href="http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ACCV_2014/pages/PDF/825.pdf" target="_blank">Plant Leaf Identification via A Growing Convolution Neural Network with Progressive Sample Learning</a></li>
</ul>

<h5>Libraries and Tools</h5>

<ul>
  <li><a href="http://jupyter.readthedocs.io/en/latest/install.html" target="_blank">Jupyter Notebook</a></li>
  <li><a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html" target="_blank">OpenCV</a></li>
  <li><a href="http://scikit-learn.org/stable/" target="_blank">Scikit-learn</a></li>
  <li><a href="http://mahotas.readthedocs.io/en/latest/" target="_blank">Mahotas</a></li>
  <li><a href="http://www.numpy.org/" target="_blank">NumPy</a></li>
  <li><a href="http://matplotlib.org/" target="_blank">SciPy</a></li>
  <li><a href="http://www.h5py.org/" target="_blank">h5Py</a></li>
</ul>

<h5>Datasets</h5>

<ul>
  <li><a href="http://leafsnap.com/dataset/" target="_blank">LeafSnap</a></li>
  <li><a href="http://www.imageclef.org/lifeclef/2016/plant" target="_blank">ImageCLEF</a></li>
  <li><a href="https://www.plantvillage.org/" target="_blank">PlantVillage</a></li>
  <li><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/17/" target="_blank">FLOWERS17</a></li>
  <li><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/" target="_blank">FLOWERS102</a></li>
  <li><a href="http://www.plant-image-analysis.org/" target="_blank">Plant Image Analysis</a></li>
</ul>
</div>

				</div>
				<div class="note closers">
	<p>In case if you found something useful to add to this article or you found a bug in the code or would like to improve some points mentioned, feel free to write it down in the comments. Hope you found something useful here.</p>
</div>
			</article>
			
			<div class="show-comments" onclick="showComments()"><p id="show_comments"><span id="comment_count" class="disqus-comment-count" data-disqus-url="https://gogulilango.com/software/image-classification-python"></span></p></div>

			<div id="disqus_thread"></div>
			<script>
				var disqus_config = function () {
				  this.page.url = 'http://localhost:4000/software/image-classification-python';
				  this.page.identifier = 'http://localhost:4000/software/image-classification-python';
				};

				(function() {
				  var d = document, s = d.createElement('script');
				  s.src = 'https://gogul09.disqus.com/embed.js';
				  s.setAttribute('data-timestamp', +new Date());
				  (d.head || d.body).appendChild(s);
				})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		</div>
	</div>
</div>

<script type="text/javascript">
	
	window.onscroll = function() {
		sideBarScrollHandler();
		windowScrollHandler();
	};
	
	function sideBarScrollHandler() {
		if (document.body.scrollTop > 350 || document.documentElement.scrollTop > 350) {
			document.getElementById("sidebar_tracker").style.top = "20px";
		} else {
			document.getElementById("sidebar_tracker").style.top = "70px";
		}
	}
	
</script>

<script type="text/javascript" src="/js/readtime.js"></script>
    </div>

    <div class="wrapper-footer">
      <footer class="footer">
        <p><span>&copy; 2024 - gogul ilango | opinions are my own</span></p>
       </footer>
     </div>

     <button onclick="topScroller()" id="btnScrollTop" title="Go to top" class="w3-animate-bottom"></button>

     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
     <script src="https://apis.google.com/js/platform.js"></script>
     <script async defer src="https://buttons.github.io/buttons.js"></script>
     <script id="dsq-count-scr" src="//gogul09.disqus.com/count.js" async></script>
     <script src="/js/custom.js"></script>
     
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-93019594-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/software/image-classification-python',
		  'title': 'Image Classification using Python and Scikit-learn'
		});
	</script>
	<!-- End Google Analytics -->

   </body>
</html>
