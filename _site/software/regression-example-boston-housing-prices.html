<!DOCTYPE html>
<html>
<head>
  <title>Predicting Housing Prices using Regression Algorithms – Gogul Ilango </title>
  
  <link rel="shortcut icon" type="image/png" href="/images/favicon_gi.png"/>
  <link rel="stylesheet" href="https://use.typekit.net/mry7nes.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Rubik:wght@300;400;500&display=swap" rel="stylesheet">

  <script type="text/javascript" src="/js/theme.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=.5, maximum-scale=12.0, minimum-scale=.25, user-scalable=yes"/>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    <meta property="og:title" content="Predicting Housing Prices using Regression Algorithms" />
    <meta name="description" content="Understand how to approach a machine learning regression problem using the boston housing prices dataset" />
    <meta property="og:description" content="Understand how to approach a machine learning regression problem using the boston housing prices dataset" />
    <meta property="twitter:title" content="Predicting Housing Prices using Regression Algorithms" />

    <meta property="og:image" content="https://drive.google.com/uc?id=1J5BYkUjjeylaMlMpvlOrPfnPLrSNTf1N"/>
    <meta property="og:image:width" content="180" />
    <meta property="og:image:height" content="110" />

    <meta name="twitter:title" content="Predicting Housing Prices using Regression Algorithms">
    <meta name="twitter:description" content="Understand how to approach a machine learning regression problem using the boston housing prices dataset">
    <meta name="twitter:image" content="https://drive.google.com/uc?id=1J5BYkUjjeylaMlMpvlOrPfnPLrSNTf1N">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Predicting Housing Prices using Regression Algorithms | Gogul Ilango</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Predicting Housing Prices using Regression Algorithms" />
<meta name="author" content="Gogul Ilango" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understand how to approach a machine learning regression problem using the boston housing prices dataset" />
<meta property="og:description" content="Understand how to approach a machine learning regression problem using the boston housing prices dataset" />
<link rel="canonical" href="http://localhost:4000/software/regression-example-boston-housing-prices" />
<meta property="og:url" content="http://localhost:4000/software/regression-example-boston-housing-prices" />
<meta property="og:site_name" content="Gogul Ilango" />
<meta property="og:image" content="https://drive.google.com/uc?id=1J5BYkUjjeylaMlMpvlOrPfnPLrSNTf1N" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-07-15T00:00:00+05:30" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://drive.google.com/uc?id=1J5BYkUjjeylaMlMpvlOrPfnPLrSNTf1N" />
<meta property="twitter:title" content="Predicting Housing Prices using Regression Algorithms" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Gogul Ilango"},"dateModified":"2018-07-15T00:00:00+05:30","datePublished":"2018-07-15T00:00:00+05:30","description":"Understand how to approach a machine learning regression problem using the boston housing prices dataset","headline":"Predicting Housing Prices using Regression Algorithms","image":"https://drive.google.com/uc?id=1J5BYkUjjeylaMlMpvlOrPfnPLrSNTf1N","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/software/regression-example-boston-housing-prices"},"url":"http://localhost:4000/software/regression-example-boston-housing-prices"}</script>
<!-- End Jekyll SEO tag -->


  <!--[if lt IE 9]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <!--[if lte IE 8]><script type="text/javascript" src="excanvas.js"></script><![endif]-->
    <meta name="theme-color" content="#000" />
    <link id="main-style-sheet" rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Gogul Ilango - This blog is a personal space of Gogul Ilango who writes about technology, music production, programming and travel." href="/feed.xml" />

  </head>

  <body>
    <div class="outer-wrapping">
      <div class="inner-container">
          <div class="topnav header-right" id="top_navigator">
            <a title="home" id = "nav_home" href="/"><span>home</span></a>
            <a title="music" id = "nav_music" href="https://www.youtube.com/gogulilangomusic" target="_blank"><span>music</span></a>
            <a title="theme" id = "nav_theme" class = "nav_theme" onclick="switchTheme(1)"><span>theme</span></a>
            <a href = "javascript:void(0);" style="font-size:14px;" class="icon" onclick="top_navigation()">&#9776;</a>
          </div>
      </div>
    </div>

    <div id="main" role="main">
      <div class="readtime-progress" id="readtime-progress"></div>

<div class="post-heading post-heading-wrapper post-image">
	<div class="grad-post">
		<h1>Predicting Housing Prices using Regression Algorithms</h1>
		<div class="post-subheading">
			<p>Machine Learning | 15 July 2018</p>
			<p><a href="#show_comments" id="comment-count" class="disqus-comment-count" data-disqus-url="https://gogulilango.com/software/regression-example-boston-housing-prices"></a></p>
		</div>
		
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<div class="share-it-box">
<div id="share-box"> 
		<a href="whatsapp://send?text=http://localhost:4000/software/regression-example-boston-housing-prices" data-action="share/whatsapp/share"><img class="icon-whatsapp" src="/images/icons/whatsapp.png"/></a>

        <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/regression-example-boston-housing-prices" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img class="icon-facebook" src="/images/icons/facebook.png"/></a>
       
        <a href="https://twitter.com/intent/tweet?text=Predicting Housing Prices using Regression Algorithms&url=http://localhost:4000/software/regression-example-boston-housing-prices" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"><img class="icon-twitter" src="/images/icons/twitter.png"/></a>

       <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/regression-example-boston-housing-prices&title=Predicting Housing Prices using Regression Algorithms&summary=Understand how to approach a machine learning regression problem using the boston housing prices dataset&source=webjeda" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img class="icon-linkedin" src="/images/icons/linkedin.png"/></a>                               
</div>
</div>
	</div>
</div>

<div class="containing">
	<div class="wrapping">

		<!--<div class="share-box">
	<button class="top-share-fab" id="top-share-fab" onclick="showShareBox(this.id)"></button>
	<div id="top-share-box" class="top-share-box">
		<h5>Share</h5>
		<ul>
			<li class="whatsapp-white"><a href="whatsapp://send?text=http://localhost:4000/software/regression-example-boston-housing-prices" data-action="share/whatsapp/share">WhatsApp</a></li>
			<li class="facebook-white"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/regression-example-boston-housing-prices" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >Facebook</a></li>
			<li class="twitter-white"><a href="https://twitter.com/intent/tweet?text=Predicting Housing Prices using Regression Algorithms&url=http://localhost:4000/software/regression-example-boston-housing-prices" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;">Twitter</a></li>
			<li class="linkedin-white"><a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/regression-example-boston-housing-prices&title=Predicting Housing Prices using Regression Algorithms&summary=Understand how to approach a machine learning regression problem using the boston housing prices dataset&source=webjeda" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >LinkedIn</a></li>
		</ul>
	</div>
</div>-->

		<div class="post-cover">
			<div class="carbon_advertisement">
				<div class="carbon_advertisement_wrapper">
					<script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CK7I623I&placement=gogul09githubio" id="_carbonads_js"></script>
				</div>
			</div>
			<article class="post">
				<div class="entry">
					<div class="sidebar_tracker" id="sidebar_tracker">
  <button onclick="closeSidebar('sidebar_tracker_content')">X</button>
  <p onclick="showSidebar('sidebar_tracker_content')">Contents</p>
  <ul id="sidebar_tracker_content">
  		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_1" href="#dependencies">Dependencies</a></li>
		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_2" href="#boston-housing-prices-dataset">Boston Housing Prices Dataset</a></li>
		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_3" href="#analyze-the-dataset">Analyze the dataset</a></li>
		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_4" href="#visualize-the-dataset">Visualize the dataset</a></li>
		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_5" href="#training-regression-models">Training regression models</a></li>
		<li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_6" href="#choosing-the-best-model">Choosing the best model</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_7" href="#references">References</a></li>
	</ul>
</div>

<div class="git-showcase">
  <div>
    <a class="github-button" href="https://github.com/Gogul09" data-show-count="true" aria-label="Follow @Gogul09 on GitHub">Follow @Gogul09</a>
  </div>

  <div>
	<a class="github-button" href="https://github.com/Gogul09/explore-machine-learning/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork Gogul09/explore-machine-learning on GitHub">Fork</a>

  </div>

  <div>
	<a class="github-button" href="https://github.com/Gogul09/explore-machine-learning" data-icon="octicon-star" data-show-count="true" aria-label="Star Gogul09/explore-machine-learning on GitHub">Star</a>
  </div>  
</div>

<p><strong>In machine learning, the ability of a model to predict continuous or real values based on a training dataset is called Regression. With a small dataset and some great python libraries, we can solve such a problem with ease.</strong></p>

<p>In this blog post, we will learn how to solve a supervised regression problem using the famous Boston housing price dataset. Other than location and square footage, a house value is determined by various other factors. Let’s analyze this problem in detail and come up with our own machine learning model to predict a housing price.</p>

<div class="objectives">
  <h3>Objectives</h3>
  <p>After reading this post, we will understand</p>
  <ul>
    <li>How to solve a supervised regression problem using python?</li>
    <li>How to analyze and visualize a regression dataset using seaborn and pandas?</li>
    <li>How to apply data transforms to the dataset that has different units?</li>
    <li>How to handle missing values in a dataset?</li>
    <li>How to find out the best regression model for our problem?</li>
    <li>How to understand which features are important to predict the target?</li>
  </ul>
</div>

<h3 id="dependencies">Dependencies</h3>

<p>I assume you have basic knowledge in installing Python and its packages using <span class="coding">pip</span> or <a href="https://anaconda.org/" target="_blank">Anaconda</a>. If not, please check my post on setting up the environment to do machine learning for <a href="https://gogul09.github.io/software/deep-learning-linux" target="_blank">linux</a> and <a href="https://gogul09.github.io/software/deep-learning-windows" target="_blank">windows</a>. To follow this tutorial, you need to have the following installed in your machine.</p>

<ul>
  <li><span class="coding">pandas</span> - To work with solid data-structures, n-dimensional matrices and perform <a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" target="_blank">exploratory data analysis</a>.</li>
  <li><span class="coding">matplotlib</span> - To visualize data using 2D plots.</li>
  <li><span class="coding">seaborn</span> - To make 2D plots look pretty and readable.</li>
  <li><span class="coding">scikit-learn</span> - To create machine learning models easily and make predictions.</li>
</ul>

<h3 id="boston-housing-prices-dataset">Boston Housing Prices Dataset</h3>
<p>In this dataset, each row describes a boston town or suburb. There are 506 rows and 13 attributes (features) with a target column (price).</p>

<p>The problem that we are going to solve here is that given a set of features that describe a house in Boston, our machine learning model must predict the house price. To train our machine learning model with boston housing data, we will be using scikit-learn’s <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" target="_blank">boston</a> dataset.</p>

<p>We will use pandas and scikit-learn to load and explore the dataset. The dataset can easily be loaded from scikit-learn’s <span class="coding">datasets</span> module using <span class="coding">load_boston</span> function.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="n">pd</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">display</span><span class="p">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">{:,.2f}</span><span class="sh">'</span><span class="p">.</span><span class="nb">format</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="nf">load_boston</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>There are four keys in this dataset using which we can access more information about the dataset. <span class="coding">data</span>, <span class="coding">target</span>, <span class="coding">feature_names</span> and <span class="coding">DESCR</span> are the four keys which could be accessed using <span class="coding">keys()</span> on the <span class="coding">dataset</span> variable.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] keys : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="nf">keys</span><span class="p">()))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>[INFO] keys : dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])
</pre></td></tr></tbody></table></code></pre></div></div>

<p>There are 13 features and 1 target that are accessed using <span class="coding">data</span> key and <span class="coding">target</span> key. We can easily access the shape of features and target using <span class="coding">shape</span>.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] features shape : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] target shape   : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>[INFO] features shape : (506, 13)
[INFO] target shape   : (506,)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The 13 column names are accessed using <span class="coding">feature_names</span> on the <span class="coding">dataset</span> which returns the unique attribute names. We can use these column names when we convert this dataset to a pandas dataframe later.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] feature names</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>[INFO] feature names
['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To know the description of each column name in this dataset, you can use <span class="coding">DESCR</span> to display the description of this dataset in a nutshell.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] dataset summary</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">DESCR</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
</pre></td><td class="rouge-code"><pre>[INFO] dataset summary
Boston House Prices dataset
===========================

Notes
------
Data Set Characteristics:

    :Number of Instances: 506

    :Number of Attributes: 13 numeric/categorical predictive

    :Median Value (attribute 14) is usually the target

    :Attribute Information (in order):
        - CRIM     per capita crime rate by town
        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
        - INDUS    proportion of non-retail business acres per town
        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
        - NOX      nitric oxides concentration (parts per 10 million)
        - RM       average number of rooms per dwelling
        - AGE      proportion of owner-occupied units built prior to 1940
        - DIS      weighted distances to five Boston employment centres
        - RAD      index of accessibility to radial highways
        - TAX      full-value property-tax rate per $10,000
        - PTRATIO  pupil-teacher ratio by town
        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
        - LSTAT    % lower status of the population
        - MEDV     Median value of owner-occupied homes in $1000's

    :Missing Attribute Values: None

    :Creator: Harrison, D. and Rubinfeld, D.L.

This is a copy of UCI ML housing dataset.
http://archive.ics.uci.edu/ml/datasets/Housing


This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.

The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic
prices and the demand for clean air', J. Environ. Economics &amp; Management,
vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics
...', Wiley, 1980.   N.B. Various transformations are used in the table on
pages 244-261 of the latter.

The Boston house-price data has been used in many machine learning papers that address regression
problems.

**References**

   - Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.
   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.
   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="analyze-the-dataset">Analyze the dataset</h3>

<p>We can easily convert the dataset into a pandas dataframe to perform exploratory data analysis. Simply pass in the <span class="coding">dataset.data</span> as an argument to <span class="coding">pd.DataFrame()</span>. We can view the first 5 rows in the dataset using <span class="coding">head()</span> function.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] df type : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">df</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] df shape: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre>[INFO] df type : &lt;class 'pandas.core.frame.DataFrame'&gt;
[INFO] df shape: (506, 13)
    0     1    2    3    4    5     6    7    8      9     10     11   12
0 0.01 18.00 2.31 0.00 0.54 6.58 65.20 4.09 1.00 296.00 15.30 396.90 4.98
1 0.03  0.00 7.07 0.00 0.47 6.42 78.90 4.97 2.00 242.00 17.80 396.90 9.14
2 0.03  0.00 7.07 0.00 0.47 7.18 61.10 4.97 2.00 242.00 17.80 392.83 4.03
3 0.03  0.00 2.18 0.00 0.46 7.00 45.80 6.06 3.00 222.00 18.70 394.63 2.94
4 0.07  0.00 2.18 0.00 0.46 7.15 54.20 6.06 3.00 222.00 18.70 396.90 5.33
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can also specify the column names <span class="coding">columns</span> of the dataframe using <span class="coding">feature_names</span> instead of the indexes shown above.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">feature_names</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre>   CRIM    ZN  INDUS  CHAS  NOX   RM   AGE  DIS  RAD    TAX  PTRATIO      B  LSTAT
0  0.01 18.00   2.31  0.00 0.54 6.58 65.20 4.09 1.00 296.00    15.30 396.90   4.98
1  0.03  0.00   7.07  0.00 0.47 6.42 78.90 4.97 2.00 242.00    17.80 396.90   9.14
2  0.03  0.00   7.07  0.00 0.47 7.18 61.10 4.97 2.00 242.00    17.80 392.83   4.03
3  0.03  0.00   2.18  0.00 0.46 7.00 45.80 6.06 3.00 222.00    18.70 394.63   2.94
4  0.07  0.00   2.18  0.00 0.46 7.15 54.20 6.06 3.00 222.00    18.70 396.90   5.33
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can also insert the <span class="coding">target</span> column in our main dataframe simply using the below code snippet.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">target</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre>   CRIM    ZN  INDUS  CHAS  NOX   RM   AGE  DIS  RAD    TAX  PTRATIO      B  LSTAT  PRICE
0  0.01 18.00   2.31  0.00 0.54 6.58 65.20 4.09 1.00 296.00    15.30 396.90   4.98  24.00
1  0.03  0.00   7.07  0.00 0.47 6.42 78.90 4.97 2.00 242.00    17.80 396.90   9.14  21.60
2  0.03  0.00   7.07  0.00 0.47 7.18 61.10 4.97 2.00 242.00    17.80 392.83   4.03  34.70
3  0.03  0.00   2.18  0.00 0.46 7.00 45.80 6.06 3.00 222.00    18.70 394.63   2.94  33.40
4  0.07  0.00   2.18  0.00 0.46 7.15 54.20 6.06 3.00 222.00    18.70 396.90   5.33  36.20
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can check the datatype of each column using <span class="coding">dtypes</span> to make sure every column has numeric datatype. If a column has different datatype such as string or character, we need to map that column to a numeric datatype such as integer or float. For this dataset, luckily there is no such column.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre>CRIM       float64
ZN         float64
INDUS      float64
CHAS       float64
NOX        float64
RM         float64
AGE        float64
DIS        float64
RAD        float64
TAX        float64
PTRATIO    float64
B          float64
LSTAT      float64
PRICE      float64
dtype: object
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now, we will understand the statistical summary of the dataset using the <span class="coding">describe()</span> function. Using this function, we can understand the count, min, max, mean and standard deviation for each attribute (column) in the dataset. Each of these can also be displayed individually using <span class="coding">df.count()</span>, <span class="coding">df.min()</span>, <span class="coding">df.max()</span>, <span class="coding">df.median()</span> and <span class="coding">df.quantile(q)</span>.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">describe</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre>        CRIM     ZN  INDUS   CHAS    NOX     RM    AGE    DIS    RAD    TAX  PTRATIO      B  LSTAT  PRICE
count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00   506.00 506.00 506.00 506.00
mean    3.59  11.36  11.14   0.07   0.55   6.28  68.57   3.80   9.55 408.24    18.46 356.67  12.65  22.53
std     8.60  23.32   6.86   0.25   0.12   0.70  28.15   2.11   8.71 168.54     2.16  91.29   7.14   9.20
min     0.01   0.00   0.46   0.00   0.39   3.56   2.90   1.13   1.00 187.00    12.60   0.32   1.73   5.00
25%     0.08   0.00   5.19   0.00   0.45   5.89  45.02   2.10   4.00 279.00    17.40 375.38   6.95  17.02
50%     0.26   0.00   9.69   0.00   0.54   6.21  77.50   3.21   5.00 330.00    19.05 391.44  11.36  21.20
75%     3.65  12.50  18.10   0.00   0.62   6.62  94.07   5.19  24.00 666.00    20.20 396.23  16.96  25.00
max    88.98 100.00  27.74   1.00   0.87   8.78 100.00  12.13  24.00 711.00    22.00 396.90  37.97  50.00
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="correlation">Correlation</h4>

<p>Finding correlation between attributes is a highly useful way to check for patterns in the dataset. Pandas offers three different ways to find correlation between attributes (columns). The output of each of these correlation functions fall within the range [-1, 1].</p>
<ul>
  <li>1 - Positively correlated</li>
  <li>-1 - Negatively correlated.</li>
  <li>0 - Not correlated.</li>
</ul>

<p>To learn more about correlation, please read this <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence" target="_blank">wikipedia</a> article. We will use <span class="coding">df.corr()</span> function to compute the correlation between attributes and <span class="coding">sns.heatmap()</span> function to visualize the correlation matrix.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="c1"># correlation between attributes
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">PEARSON CORRELATION</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">pearson</span><span class="sh">"</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">pearson</span><span class="sh">"</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">heatmap_pearson.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">SPEARMAN CORRELATION</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">spearman</span><span class="sh">"</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">spearman</span><span class="sh">"</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">heatmap_spearman.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">KENDALL CORRELATION</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">kendall</span><span class="sh">"</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">kendall</span><span class="sh">"</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">heatmap_kendall.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td><td class="rouge-code"><pre>PEARSON CORRELATION
         CRIM    ZN  INDUS  CHAS   NOX    RM   AGE   DIS   RAD   TAX  PTRATIO     B  LSTAT  PRICE
CRIM     1.00 -0.20   0.40 -0.06  0.42 -0.22  0.35 -0.38  0.62  0.58     0.29 -0.38   0.45  -0.39
ZN      -0.20  1.00  -0.53 -0.04 -0.52  0.31 -0.57  0.66 -0.31 -0.31    -0.39  0.18  -0.41   0.36
INDUS    0.40 -0.53   1.00  0.06  0.76 -0.39  0.64 -0.71  0.60  0.72     0.38 -0.36   0.60  -0.48
CHAS    -0.06 -0.04   0.06  1.00  0.09  0.09  0.09 -0.10 -0.01 -0.04    -0.12  0.05  -0.05   0.18
NOX      0.42 -0.52   0.76  0.09  1.00 -0.30  0.73 -0.77  0.61  0.67     0.19 -0.38   0.59  -0.43
RM      -0.22  0.31  -0.39  0.09 -0.30  1.00 -0.24  0.21 -0.21 -0.29    -0.36  0.13  -0.61   0.70
AGE      0.35 -0.57   0.64  0.09  0.73 -0.24  1.00 -0.75  0.46  0.51     0.26 -0.27   0.60  -0.38
DIS     -0.38  0.66  -0.71 -0.10 -0.77  0.21 -0.75  1.00 -0.49 -0.53    -0.23  0.29  -0.50   0.25
RAD      0.62 -0.31   0.60 -0.01  0.61 -0.21  0.46 -0.49  1.00  0.91     0.46 -0.44   0.49  -0.38
TAX      0.58 -0.31   0.72 -0.04  0.67 -0.29  0.51 -0.53  0.91  1.00     0.46 -0.44   0.54  -0.47
PTRATIO  0.29 -0.39   0.38 -0.12  0.19 -0.36  0.26 -0.23  0.46  0.46     1.00 -0.18   0.37  -0.51
B       -0.38  0.18  -0.36  0.05 -0.38  0.13 -0.27  0.29 -0.44 -0.44    -0.18  1.00  -0.37   0.33
LSTAT    0.45 -0.41   0.60 -0.05  0.59 -0.61  0.60 -0.50  0.49  0.54     0.37 -0.37   1.00  -0.74
PRICE   -0.39  0.36  -0.48  0.18 -0.43  0.70 -0.38  0.25 -0.38 -0.47    -0.51  0.33  -0.74   1.00

SPEARMAN CORRELATION
         CRIM    ZN  INDUS  CHAS   NOX    RM   AGE   DIS   RAD   TAX  PTRATIO     B  LSTAT  PRICE
CRIM     1.00 -0.57   0.74  0.04  0.82 -0.31  0.70 -0.74  0.73  0.73     0.46 -0.36   0.63  -0.56
ZN      -0.57  1.00  -0.64 -0.04 -0.63  0.36 -0.54  0.61 -0.28 -0.37    -0.45  0.16  -0.49   0.44
INDUS    0.74 -0.64   1.00  0.09  0.79 -0.42  0.68 -0.76  0.46  0.66     0.43 -0.29   0.64  -0.58
CHAS     0.04 -0.04   0.09  1.00  0.07  0.06  0.07 -0.08  0.02 -0.04    -0.14 -0.04  -0.05   0.14
NOX      0.82 -0.63   0.79  0.07  1.00 -0.31  0.80 -0.88  0.59  0.65     0.39 -0.30   0.64  -0.56
RM      -0.31  0.36  -0.42  0.06 -0.31  1.00 -0.28  0.26 -0.11 -0.27    -0.31  0.05  -0.64   0.63
AGE      0.70 -0.54   0.68  0.07  0.80 -0.28  1.00 -0.80  0.42  0.53     0.36 -0.23   0.66  -0.55
DIS     -0.74  0.61  -0.76 -0.08 -0.88  0.26 -0.80  1.00 -0.50 -0.57    -0.32  0.25  -0.56   0.45
RAD      0.73 -0.28   0.46  0.02  0.59 -0.11  0.42 -0.50  1.00  0.70     0.32 -0.28   0.39  -0.35
TAX      0.73 -0.37   0.66 -0.04  0.65 -0.27  0.53 -0.57  0.70  1.00     0.45 -0.33   0.53  -0.56
PTRATIO  0.46 -0.45   0.43 -0.14  0.39 -0.31  0.36 -0.32  0.32  0.45     1.00 -0.07   0.47  -0.56
B       -0.36  0.16  -0.29 -0.04 -0.30  0.05 -0.23  0.25 -0.28 -0.33    -0.07  1.00  -0.21   0.19
LSTAT    0.63 -0.49   0.64 -0.05  0.64 -0.64  0.66 -0.56  0.39  0.53     0.47 -0.21   1.00  -0.85
PRICE   -0.56  0.44  -0.58  0.14 -0.56  0.63 -0.55  0.45 -0.35 -0.56    -0.56  0.19  -0.85   1.00

KENDALL CORRELATION
         CRIM    ZN  INDUS  CHAS   NOX    RM   AGE   DIS   RAD   TAX  PTRATIO     B  LSTAT  PRICE
CRIM     1.00 -0.46   0.52  0.03  0.60 -0.21  0.50 -0.54  0.56  0.54     0.31 -0.26   0.45  -0.40
ZN      -0.46  1.00  -0.54 -0.04 -0.51  0.28 -0.43  0.48 -0.23 -0.29    -0.36  0.13  -0.39   0.34
INDUS    0.52 -0.54   1.00  0.08  0.61 -0.29  0.49 -0.57  0.35  0.48     0.34 -0.19   0.47  -0.42
CHAS     0.03 -0.04   0.08  1.00  0.06  0.05  0.06 -0.07  0.02 -0.04    -0.12 -0.03  -0.04   0.12
NOX      0.60 -0.51   0.61  0.06  1.00 -0.22  0.59 -0.68  0.43  0.45     0.28 -0.20   0.45  -0.39
RM      -0.21  0.28  -0.29  0.05 -0.22  1.00 -0.19  0.18 -0.08 -0.19    -0.22  0.03  -0.47   0.48
AGE      0.50 -0.43   0.49  0.06  0.59 -0.19  1.00 -0.61  0.31  0.36     0.25 -0.15   0.49  -0.39
DIS     -0.54  0.48  -0.57 -0.07 -0.68  0.18 -0.61  1.00 -0.36 -0.38    -0.22  0.17  -0.41   0.31
RAD      0.56 -0.23   0.35  0.02  0.43 -0.08  0.31 -0.36  1.00  0.56     0.25 -0.21   0.29  -0.25
TAX      0.54 -0.29   0.48 -0.04  0.45 -0.19  0.36 -0.38  0.56  1.00     0.29 -0.24   0.38  -0.41
PTRATIO  0.31 -0.36   0.34 -0.12  0.28 -0.22  0.25 -0.22  0.25  0.29     1.00 -0.04   0.33  -0.40
B       -0.26  0.13  -0.19 -0.03 -0.20  0.03 -0.15  0.17 -0.21 -0.24    -0.04  1.00  -0.15   0.13
LSTAT    0.45 -0.39   0.47 -0.04  0.45 -0.47  0.49 -0.41  0.29  0.38     0.33 -0.15   1.00  -0.67
PRICE   -0.40  0.34  -0.42  0.12 -0.39  0.48 -0.39  0.31 -0.25 -0.41    -0.40  0.13  -0.67   1.00
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
	<select id="select_heatmap_plot" onchange="selectBoxHandler('heatmap', this.id,'/images/software/machine-learning/boston-housing-prices/correlation/', 'img_heatmap_plot')">
		<option id="0" value="pearson">PEARSON</option>
		<option id="1" value="spearman ">SPEARMAN</option>
		<option id="2" value="kendall">KENDALL</option>
	</select>
<div class="img_container">
	<img id="img_heatmap_plot" src="/images/software/machine-learning/boston-housing-prices/correlation/heatmap_0.png" />
</div>
<figcaption>Figure 1. Correlation heatmaps</figcaption>
</figure>

<h4 id="missing-values">Missing Values</h4>

<p>Sometimes, in a dataset we will have missing values such as <span class="coding">NaN</span> or empty string in a cell. We need to take care of these missing values so that our machine learning model doesn’t break. To handle missing values, there are three approaches followed.</p>

<ul>
  <li>Replace the missing value with a large negative number (e.g. -999).</li>
  <li>Replace the missing value with mean of the column.</li>
  <li>Replace the missing value with median of the column.</li>
</ul>

<p>To find if a column in our dataset has missing values, you can use <span class="coding">pd.isnull(df).any()</span> which returns a boolean for each column in the dataset that tells if the column contains any missing value. In this dataset, there are no missing values!</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="nf">any</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre>CRIM       False 
ZN         False 
INDUS      False 
CHAS       False 
NOX        False 
RM         False 
AGE        False 
DIS        False 
RAD        False 
TAX        False 
PTRATIO    False 
B          False 
LSTAT      False 
PRICE      False 
dtype: bool      
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Once a dataset is available to us, it is always good to generate a brief report that gives lots of statistical information about the dataset so that you get to know the structure or nature of the dataset. You can use the below code snippet to generate a report like <a href="https://github.com/Gogul09/explore-machine-learning/blob/master/regression/boston_housing_prices/boston_housing.txt" target="_blank">this</a>.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="rouge-code"><pre><span class="n">file_report</span> <span class="o">=</span> <span class="sh">"</span><span class="s">boston_housing.txt</span><span class="sh">"</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_report</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="s">Features shape : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="s">Target shape   : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Column names</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Statistical summary</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">describe</span><span class="p">()))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Datatypes</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span><span class="p">))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">PEARSON correlation</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">pearson</span><span class="sh">"</span><span class="p">)))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">SPEARMAN correlation</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">spearman</span><span class="sh">"</span><span class="p">)))</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">KENDALL correlation</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="sh">"</span><span class="s">kendall</span><span class="sh">"</span><span class="p">)))</span>

  <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Missing Values</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="nf">any</span><span class="p">()))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="visualize-the-dataset">Visualize the dataset</h3>

<p>We will use two types of visualization strategy namely univariate plots and bivariate plots. As the name suggests, univariate plot is used to visualize a single column or an attribute whereas bivariate plot is used to visualize two columns or two attributes.</p>

<h4 id="box-plot">Box plot</h4>

<p>A box-whisker plot is a univariate plot used to visualize a data distribution.</p>
<ul>
  <li>The ends of whiskers are the maximum and minimum range of data distribution.</li>
  <li>The central line in the box is the median of the entire data distribution.</li>
  <li>The right and left edges in the box are the medians of data distribution to the right and left from the central median, respectively.</li>
</ul>

<p>Understand more about box plots <a href="https://www.khanacademy.org/math/ap-statistics/summarizing-quantitative-data-ap/stats-box-whisker-plots/v/reading-box-and-whisker-plots" target="_blank">here</a>.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="c1"># visualize the dataset
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">color_codes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">g</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">]</span>

<span class="n">cols</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/box</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/box</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># draw a boxplot with vertical orientation
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
	<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">colors</span><span class="p">),</span> <span class="n">orient</span><span class="o">=</span><span class="sh">"</span><span class="s">v</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/box/box_</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
	<select id="select_box_plot" onchange="selectBoxHandler('box', this.id,'/images/software/machine-learning/boston-housing-prices/plots/univariate/box/', 'img_box_plot')">
		<option id="0" value="crim">CRIM</option>
		<option id="1" value="zn ">ZN</option>
		<option id="2" value="indus">INDUS</option>
		<option id="3" value="chas">CHAS</option>
		<option id="4" value="nox">NOX</option>
		<option id="5" value="rm">RM</option>
		<option id="6" value="age">AGE</option>
		<option id="7" value="dis">DIS</option>
		<option id="8" value="rad">RAD</option>
		<option id="9" value="tax">TAX</option>
		<option id="10" value="ptratio">PTRATIO</option>
		<option id="11" value="b">B</option>
		<option id="12" value="lstat">LSTAT</option>
		<option id="13" value="price">PRICE</option>
	</select>
<div class="img_container">
	<img id="img_box_plot" src="/images/software/machine-learning/boston-housing-prices/plots/univariate/box/box_0.png" />
</div>
<figcaption>Figure 2. Box plots</figcaption>
</figure>

<p>Using the box plots, we could see that there are outliers in the dataset for attributes such as <span class="coding">CRIM</span>, <span class="coding">ZN</span>, <span class="coding">CHAS</span>, <span class="coding">DIS</span>, <span class="coding">PTRATIO</span>, <span class="coding">LSTAT</span>, <span class="coding">B</span> and <span class="coding">PRICE</span>.</p>

<h4 id="density-plot">Density plot</h4>

<p>Density plot is another univariate plot that draws a histogram of the data distribution and fits a Kernel Density Estimate (KDE).</p>

<p>A histogram is a graphical representation of a frequency distribution where data points are organized as bins, plotted with values along the x-axis and the count of data points in each bin along the y-axis.</p>

<p>A <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation" target="_blank">Kernel Density Plot</a> shows a smooth representation of the data points.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/density</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/density</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># draw a histogram and fit a kernel density estimate (KDE)
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
	<span class="n">sns</span><span class="p">.</span><span class="nf">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">colors</span><span class="p">))</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/univariate/density/density_</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
	<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
	<select id="select_density_plot" onchange="selectBoxHandler('density', this.id,'/images/software/machine-learning/boston-housing-prices/plots/univariate/density/', 'img_density_plot')">
		<option id="0" value="crim">CRIM</option>
		<option id="1" value="zn ">ZN</option>
		<option id="2" value="indus">INDUS</option>
		<option id="3" value="chas">CHAS</option>
		<option id="4" value="nox">NOX</option>
		<option id="5" value="rm">RM</option>
		<option id="6" value="age">AGE</option>
		<option id="7" value="dis">DIS</option>
		<option id="8" value="rad">RAD</option>
		<option id="9" value="tax">TAX</option>
		<option id="10" value="ptratio">PTRATIO</option>
		<option id="11" value="b">B</option>
		<option id="12" value="lstat">LSTAT</option>
		<option id="13" value="price">PRICE</option>
	</select>
<div class="img_container">
	<img id="img_density_plot" src="/images/software/machine-learning/boston-housing-prices/plots/univariate/density/density_0.png" />
</div>
<figcaption>Figure 3. Density plots</figcaption>
</figure>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/multivariate</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/multivariate</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># bivariate plot between target and reason of absence
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
	<span class="nf">if </span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
		<span class="k">pass</span>
	<span class="k">else</span><span class="p">:</span> 
		<span class="n">sns</span><span class="p">.</span><span class="nf">jointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">);</span>
		<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/multivariate/target_vs_</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
		<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
		<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Using the density plots, we can see that <span class="coding">CRIM</span>, <span class="coding">AGE</span>, <span class="coding">B</span> and <span class="coding">ZN</span> have exponential distribution. <span class="coding">NOX</span>, <span class="coding">RM</span> and <span class="coding">LSTAT</span> is probably having a skewed gaussian distribution. Also, we could notice that <span class="coding">RAD</span> and <span class="coding">TAX</span> have bimodal distribution.</p>

<h4 id="scatter-plot">Scatter plot</h4>

<p>Scatter plot is used to understand relationship between two different attributes in the dataset. Below we have compared <span class="coding">PRICE</span> (target) vs each of the attribute in the dataset.</p>
<figure>
	<select id="select_scatter_plot" onchange="selectBoxHandler('target_vs_', this.id,'/images/software/machine-learning/boston-housing-prices/plots/multivariate/', 'img_scatter_plot')">
		<option id="0" value="crim">CRIM</option>
		<option id="1" value="zn ">ZN</option>
		<option id="2" value="indus">INDUS</option>
		<option id="3" value="chas">CHAS</option>
		<option id="4" value="nox">NOX</option>
		<option id="5" value="rm">RM</option>
		<option id="6" value="age">AGE</option>
		<option id="7" value="dis">DIS</option>
		<option id="8" value="rad">RAD</option>
		<option id="9" value="tax">TAX</option>
		<option id="10" value="ptratio">PTRATIO</option>
		<option id="11" value="b">B</option>
		<option id="12" value="lstat">LSTAT</option>
	</select>
<div class="img_container">
	<img id="img_scatter_plot" src="/images/software/machine-learning/boston-housing-prices/plots/multivariate/target_vs_0.png" />
</div>
<figcaption>Figure 4. Scatter plots</figcaption>
</figure>

<h4 id="pairplot">Pairplot</h4>

<p>For each pair of features (columns) in the dataset, we can visualize the scatter plot for each pair along with the feature’s histogram along the diagonal in a single image using <span class="coding">sns.pairplot()</span> function.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1"># pairplot
</span><span class="n">sns</span><span class="p">.</span><span class="nf">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">plots/pairplot.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
  <img src="/images/software/machine-learning/boston-housing-prices/plots/pairplot.png" />
<figcaption>Figure 5. Pairplot</figcaption>
</figure>

<p>We see a lot of structure in this dataset with outliers and different data distributions. Two key take aways from these visualizations are</p>

<ul>
  <li>Data is not standardized (meaning there are different data distributions).</li>
  <li>Data is not normalized (meaning there are differing scales of data).</li>
</ul>

<h3 id="training-regression-models">Training regression models</h3>

<p>By looking at the dataset, we simply can’t suggest the best regression model for this problem. So, we will try out different regression models available in scikit-learn with a 10-fold cross validation method.</p>

<p>It means we split the training data into <span class="coding">train</span> and <span class="coding">test</span> data using a <span class="coding">test_size</span> parameter for 10-folds. Each fold will have different samples that are not present in other folds. By this way, we can throughly train our model on different samples in the dataset.</p>

<p>Before doing anything, we will split our boston housing prices dataframe <span class="coding">df</span> into features <span class="coding">X</span> and target <span class="coding">Y</span>.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>(506, 13)
(506,)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As we see different data distributions, we will standardize the dataset using <span class="coding">StandardScaler</span> function in scikit-learn. This is a useful technique where the attributes are transformed to a standard gaussian distribution with a mean of 0 and a standard deviation of 1.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">scaled_X</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now, we will split the data into <span class="coding">train</span> and <span class="coding">test</span> set. We can easily do this using scikit-learn’s <span class="coding">train_test_split()</span> function using a <span class="coding">test_size</span> parameter.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">seed</span>      <span class="o">=</span> <span class="mi">9</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">scaled_X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">Y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>(404, 13)
(102, 13)
(404,)   
(102,)    
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Let’s dive into regression. We will use different regression models offered by scikit-learn to produce a baseline accuracy for this problem. We will use the <span class="coding">MSE</span> (Mean Squared Error) as the performance metric for the regression models.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c1"># user variables to tune
</span><span class="n">folds</span>   <span class="o">=</span> <span class="mi">10</span>
<span class="n">metric</span>  <span class="o">=</span> <span class="sh">"</span><span class="s">neg_mean_squared_error</span><span class="sh">"</span>

<span class="c1"># hold different regression models in a single dictionary
</span><span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">Linear</span><span class="sh">"</span><span class="p">]</span>        <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">Lasso</span><span class="sh">"</span><span class="p">]</span>         <span class="o">=</span> <span class="nc">Lasso</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">ElasticNet</span><span class="sh">"</span><span class="p">]</span>    <span class="o">=</span> <span class="nc">ElasticNet</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">KNN</span><span class="sh">"</span><span class="p">]</span>           <span class="o">=</span> <span class="nc">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">DecisionTree</span><span class="sh">"</span><span class="p">]</span>  <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">SVR</span><span class="sh">"</span><span class="p">]</span>           <span class="o">=</span> <span class="nc">SVR</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">AdaBoost</span><span class="sh">"</span><span class="p">]</span>      <span class="o">=</span> <span class="nc">AdaBoostRegressor</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">GradientBoost</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nc">GradientBoostingRegressor</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">RandomForest</span><span class="sh">"</span><span class="p">]</span>  <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">()</span>
<span class="n">models</span><span class="p">[</span><span class="sh">"</span><span class="s">ExtraTrees</span><span class="sh">"</span><span class="p">]</span>    <span class="o">=</span> <span class="nc">ExtraTreesRegressor</span><span class="p">()</span>

<span class="c1"># 10-fold cross validation for each model
</span><span class="n">model_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model_names</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
	<span class="n">model</span>   <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
	<span class="n">k_fold</span>  <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
	<span class="n">results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">k_fold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
	
	<span class="n">model_results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
	<span class="n">model_names</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
	<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">{}: {}, {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="nf">round</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="nf">mean</span><span class="p">(),</span> <span class="mi">3</span><span class="p">),</span> <span class="nf">round</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="nf">std</span><span class="p">(),</span> <span class="mi">3</span><span class="p">)))</span>

<span class="c1"># box-whisker plot to compare regression models
</span><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">figure</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Regression models comparison</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="n">figure</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">model_results</span><span class="p">)</span>
<span class="n">axis</span><span class="p">.</span><span class="nf">set_xticklabels</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">rotation</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">)</span>
<span class="n">axis</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Mean Squared Error (MSE)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">margins</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">model_mse_scores.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre>Linear        : -23.794, 12.358
Lasso         : -63.82,  20.646
ElasticNet    : -69.362, 21.371
KNN           : -26.366, 16.169
DecisionTree  : -26.64,  13.894
SVR           : -53.247, 22.157
AdaBoost      : -13.846,  5.635
GradientBoost : -10.247,  5.328
RandomForest  : -12.418,  6.976
ExtraTrees    : -11.568,  7.065
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
	<img src="/images/software/machine-learning/boston-housing-prices/model_mse_scores.png" />
<figcaption>Figure 5. Regression models comparison</figcaption>
</figure>

<h3 id="choosing-the-best-model">Choosing the best model</h3>

<p>Based on the above comparison, we can see that Gradient Boosting Regression model outperforms all the other regression models. So, we will choose it as the best regression model for this problem.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="c1"># create and fit the best regression model
</span><span class="n">best_model</span> <span class="o">=</span> <span class="nc">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">best_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># make predictions using the model
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[INFO] MSE : {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">),</span> <span class="mi">3</span><span class="p">)))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext code-out highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>[INFO] MSE : 9.961
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Finally, we can see that Gradient Boosting Regression model achieved a mean squared error of 9.961 which means our model is able to predict correct values on test data with MSE of 9.961. We can visualize the <span class="coding">predictions</span> made by our best model and the original targets <span class="coding">Y_test</span> using the below code.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># plot between predictions and Y_test
</span><span class="n">x_axis</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">predictions</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">"</span><span class="s">--</span><span class="sh">"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">"</span><span class="s">o</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">predictions</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">"</span><span class="s">--</span><span class="sh">"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">"</span><span class="s">o</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Y_test</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Row number</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">PRICE</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Predictions vs Y_test</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">lower right</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">predictions_vs_ytest.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
	<img src="/images/software/machine-learning/boston-housing-prices/predictions_vs_ytest.png" />
<figcaption>Figure 6. Predictions vs Y_test</figcaption>
</figure>

<p>We could still tune different regression models used in this example using scikit-learn’s <span class="coding">GridSearchCV()</span> function. By tuning, we mean trying out different hyper-parameters for each model. You can check <a href="http://scikit-learn.org/stable/modules/grid_search.html" target="_blank">this</a> post to perform hyperparameter tuning.</p>

<h4 id="feature-importance">Feature Importance</h4>

<p>Once we have a trained model, we can understand feature importance (or variable importance) of the dataset which tells us how important each feature is, to predict the target. Figure 7 shows relative importance of different feature in the dataset made by our best model Gradient Boosting Regressor (GBR).</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="c1"># plot model's feature importance
</span><span class="n">feature_importance</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">feature_importance</span> <span class="o">/</span> <span class="n">feature_importance</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>

<span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">)</span>
<span class="n">pos</span>        <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">sorted_idx</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="p">.</span><span class="mi">5</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">feature_importance</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Relative Importance</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Variable Importance</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">feature_importance.png</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<figure>
  <img src="/images/software/machine-learning/boston-housing-prices/feature_importance.png" />
<figcaption>Figure 7. Feature Importance (GBR model)</figcaption>
</figure>

<div class="references">
<h3 id="references">References</h3>
<ul>
  <li><a href="http://www.neural.cz/dataset-exploration-boston-house-pricing.html" target="_blank">Dataset exploration: Boston house pricing</a></li>
  <li><a href="https://www.scipy-lectures.org/packages/scikit-learn/auto_examples/plot_boston_prediction.html" target="_blank">A simple regression analysis on the Boston housing data</a></li>
  <li><a href="https://medium.com/@haydar_ai/learning-data-science-day-9-linear-regression-on-boston-housing-dataset-cd62a80775ef" target="_blank">Learning Data Science: Day 9 - Linear Regression on Boston Housing Dataset</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" target="_blank">sklearn.datasets.load_boston</a></li>
  <li><a href="https://www.ritchieng.com/machine-learning-project-boston-home-prices/" target="_blank">Predicting Boston Housing Prices</a></li>
  <li><a href="https://www.kaggle.com/erick5/predicting-house-prices-with-machine-learning" target="_blank">Predicting House Prices with Machine Learning</a></li>
</ul>
</div>

<script type="text/javascript" src="/js/selectbox.js"></script>


				</div>
				<div class="note closers">
	<p>In case if you found something useful to add to this article or you found a bug in the code or would like to improve some points mentioned, feel free to write it down in the comments. Hope you found something useful here.</p>
</div>
			</article>
			
			<div class="show-comments" onclick="showComments()"><p id="show_comments"><span id="comment_count" class="disqus-comment-count" data-disqus-url="https://gogulilango.com/software/regression-example-boston-housing-prices"></span></p></div>

			<div id="disqus_thread"></div>
			<script>
				var disqus_config = function () {
				  this.page.url = 'http://localhost:4000/software/regression-example-boston-housing-prices';
				  this.page.identifier = 'http://localhost:4000/software/regression-example-boston-housing-prices';
				};

				(function() {
				  var d = document, s = d.createElement('script');
				  s.src = 'https://gogul09.disqus.com/embed.js';
				  s.setAttribute('data-timestamp', +new Date());
				  (d.head || d.body).appendChild(s);
				})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		</div>
	</div>
</div>

<script type="text/javascript">
	
	window.onscroll = function() {
		sideBarScrollHandler();
		windowScrollHandler();
	};
	
	function sideBarScrollHandler() {
		if (document.body.scrollTop > 350 || document.documentElement.scrollTop > 350) {
			document.getElementById("sidebar_tracker").style.top = "20px";
		} else {
			document.getElementById("sidebar_tracker").style.top = "70px";
		}
	}
	
</script>

<script type="text/javascript" src="/js/readtime.js"></script>
    </div>

    <div class="wrapper-footer">
      <footer class="footer">
        <p><span>&copy; 2024 - gogul ilango | opinions are my own</span></p>
       </footer>
     </div>

     <button onclick="topScroller()" id="btnScrollTop" title="Go to top" class="w3-animate-bottom"></button>

     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
     <script src="https://apis.google.com/js/platform.js"></script>
     <script async defer src="https://buttons.github.io/buttons.js"></script>
     <script id="dsq-count-scr" src="//gogul09.disqus.com/count.js" async></script>
     <script src="/js/custom.js"></script>
     
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-93019594-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/software/regression-example-boston-housing-prices',
		  'title': 'Predicting Housing Prices using Regression Algorithms'
		});
	</script>
	<!-- End Google Analytics -->

   </body>
</html>
